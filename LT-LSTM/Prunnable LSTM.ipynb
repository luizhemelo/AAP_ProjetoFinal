{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device dynamic memory allocation failed!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, GlobalMaxPooling1D, SpatialDropout1D\n",
    "\n",
    "#Tries to enable dynamic memory allocation on GP\n",
    "try:\n",
    "\tfor i in tensorflow.config.experimental.list_physical_devices(\"GPU\"):\n",
    "\t\ttensorflow.config.experimental.set_memory_growth(i, True)\n",
    "except:\n",
    "\tprint(\"Device dynamic memory allocation failed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrunnableLSTMCell(layers.LSTMCell):\n",
    "    \"\"\"Custom LSTM Class for prunning weights\"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(PrunnableLSTMCell, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        self.trainable_channels = None\n",
    "        self.trainable_recurrent_channels = None\n",
    "        self.trainable_bias = None\n",
    "        \n",
    "        self._kernel1 = None\n",
    "        self._kernel2 = None\n",
    "        \n",
    "        self._recurrent_kernel1 = None\n",
    "        self._recurrent_kernel2 = None\n",
    "        \n",
    "        self._bias1 = None\n",
    "        self._bias2 = None\n",
    "        \n",
    "        self.saved_W = None\n",
    "        self.saved_recW = None\n",
    "        self.saved_bias = None\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        input_dim = input_shape[-1]\n",
    "\n",
    "        if type(self.recurrent_initializer).__name__ == 'Identity':\n",
    "            def recurrent_identity(shape, gain=1., dtype=None):\n",
    "                del dtype\n",
    "                return gain * np.concatenate(\n",
    "                    [np.identity(shape[0])] * (shape[1] // shape[0]), axis=1)\n",
    "\n",
    "            self.recurrent_initializer = recurrent_identity\n",
    "\n",
    "        self._kernel1 = self.add_weight(shape=(input_dim, self.units * 4),name='kernel',\n",
    "                                        initializer=self.kernel_initializer,\n",
    "                                        regularizer=self.kernel_regularizer,\n",
    "                                        constraint=self.kernel_constraint)\n",
    "        \n",
    "        self.recurrent_kernel1 = self.add_weight(\n",
    "                                        shape=(self.units, self.units * 4),\n",
    "                                        name='recurrent_kernel',\n",
    "                                        initializer=self.recurrent_initializer,\n",
    "                                        regularizer=self.recurrent_regularizer,\n",
    "                                        constraint=self.recurrent_constraint)\n",
    "        \n",
    "        self.trainable_channels = tensorflow.ones((input_dim, self.units*4), dtype=tensorflow.uint8)\n",
    "        self.trainable_recurrent_channels = tensorflow.ones((input_dim, self.units*4), dtype=tensorflow.uint8)\n",
    "        \n",
    "        self._kernel2 = tensorflow.zeros((input_dim, self.units*4))\n",
    "        self._recurrent_kernel2 = tensorflow.zeros((input_dim, self.units*4))\n",
    "        \n",
    "        \n",
    "        if self.use_bias:\n",
    "            if self.unit_forget_bias:\n",
    "                @K.eager\n",
    "                def bias_initializer(_, *args, **kwargs):\n",
    "                    return K.concatenate([\n",
    "                        self.bias_initializer((self.units,), *args, **kwargs),\n",
    "                        initializers.Ones()((self.units,), *args, **kwargs),\n",
    "                        self.bias_initializer((self.units * 2,), *args, **kwargs),\n",
    "                    ])\n",
    "            else:\n",
    "                bias_initializer = self.bias_initializer\n",
    "            self._bias1 = self.add_weight(shape=(self.units * 4,),      #inicializa bias1\n",
    "                                        name='bias',\n",
    "                                        initializer=bias_initializer,\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "            self._bias2 = tensorflow.zeros((self.units * 4,))     #inicializa bias2\n",
    "        else:\n",
    "            self._bias1 = None\n",
    "\n",
    "        self._kernel1_i = self._kernel1[:, :self.units]\n",
    "        self._kernel1_f = self._kernel1[:, self.units: self.units * 2]\n",
    "        self._kernel1_c = self._kernel1[:, self.units * 2: self.units * 3]\n",
    "        self._kernel1_o = self._kernel1[:, self.units * 3:]\n",
    "\n",
    "        self.recurrent_kernel_i = self.recurrent_kernel[:, :self.units]\n",
    "        self.recurrent_kernel_f = (self.recurrent_kernel[:, self.units: self.units * 2])\n",
    "        self.recurrent_kernel_c = (self.recurrent_kernel[:, self.units * 2: self.units * 3])\n",
    "        self.recurrent_kernel_o = self.recurrent_kernel[:, self.units * 3:]\n",
    "\n",
    "        if self.use_bias:\n",
    "            self._bias1_i = self._bias1[:self.units]\n",
    "            self._bias1_f = self._bias1[self.units: self.units * 2]\n",
    "            self._bias1_c = self._bias1[self.units * 2: self.units * 3]\n",
    "            self._bias1_o = self._bias1[self.units * 3:]\n",
    "        else:\n",
    "            self._bias1_i = None\n",
    "            self._bias1_f = None\n",
    "            self._bias1_c = None\n",
    "            self._bias1_o = None\n",
    "        self.built = True\n",
    "    \n",
    "    def call(self, inputs, states, training=None):\n",
    "        if 0 < self.dropout < 1 and self._dropout_mask is None:\n",
    "            self._dropout_mask = _generate_dropout_mask(\n",
    "                K.ones_like(inputs),\n",
    "                self.dropout,\n",
    "                training=training,\n",
    "                count=4)\n",
    "        if (0 < self.recurrent_dropout < 1 and\n",
    "                self._recurrent_dropout_mask is None):\n",
    "            self._recurrent_dropout_mask = _generate_dropout_mask(\n",
    "                K.ones_like(states[0]),\n",
    "                self.recurrent_dropout,\n",
    "                training=training,\n",
    "                count=4)\n",
    "\n",
    "        # dropout matrices for input units\n",
    "        dp_mask = self._dropout_mask\n",
    "        # dropout matrices for recurrent units\n",
    "        rec_dp_mask = self._recurrent_dropout_mask\n",
    "\n",
    "        h_tm1 = states[0]  # previous memory state\n",
    "        c_tm1 = states[1]  # previous carry state\n",
    "\n",
    "        if self.implementation == 1:\n",
    "            if 0 < self.dropout < 1.:\n",
    "                inputs_i = inputs * dp_mask[0]\n",
    "                inputs_f = inputs * dp_mask[1]\n",
    "                inputs_c = inputs * dp_mask[2]\n",
    "                inputs_o = inputs * dp_mask[3]\n",
    "            else:\n",
    "                inputs_i = inputs\n",
    "                inputs_f = inputs\n",
    "                inputs_c = inputs\n",
    "                inputs_o = inputs\n",
    "            x_i = K.dot(inputs_i, self.kernel_i)\n",
    "            x_f = K.dot(inputs_f, self.kernel_f)\n",
    "            x_c = K.dot(inputs_c, self.kernel_c)\n",
    "            x_o = K.dot(inputs_o, self.kernel_o)\n",
    "            if self.use_bias:\n",
    "                x_i = K.bias_add(x_i, self.bias_i)\n",
    "                x_f = K.bias_add(x_f, self.bias_f)\n",
    "                x_c = K.bias_add(x_c, self.bias_c)\n",
    "                x_o = K.bias_add(x_o, self.bias_o)\n",
    "\n",
    "            if 0 < self.recurrent_dropout < 1.:\n",
    "                h_tm1_i = h_tm1 * rec_dp_mask[0]\n",
    "                h_tm1_f = h_tm1 * rec_dp_mask[1]\n",
    "                h_tm1_c = h_tm1 * rec_dp_mask[2]\n",
    "                h_tm1_o = h_tm1 * rec_dp_mask[3]\n",
    "            else:\n",
    "                h_tm1_i = h_tm1\n",
    "                h_tm1_f = h_tm1\n",
    "                h_tm1_c = h_tm1\n",
    "                h_tm1_o = h_tm1\n",
    "            i = self.recurrent_activation(x_i + K.dot(h_tm1_i,\n",
    "                                                      self.recurrent_kernel_i))\n",
    "            f = self.recurrent_activation(x_f + K.dot(h_tm1_f,\n",
    "                                                      self.recurrent_kernel_f))\n",
    "            c = f * c_tm1 + i * self.activation(x_c + K.dot(h_tm1_c,\n",
    "                                                            self.recurrent_kernel_c))\n",
    "            o = self.recurrent_activation(x_o + K.dot(h_tm1_o,\n",
    "                                                      self.recurrent_kernel_o))\n",
    "        else:\n",
    "            if 0. < self.dropout < 1.:\n",
    "                inputs *= dp_mask[0]\n",
    "            z = K.dot(inputs, self.kernel)\n",
    "            if 0. < self.recurrent_dropout < 1.:\n",
    "                h_tm1 *= rec_dp_mask[0]\n",
    "            z += K.dot(h_tm1, self.recurrent_kernel)\n",
    "            if self.use_bias:\n",
    "                z = K.bias_add(z, self.bias)\n",
    "\n",
    "            z0 = z[:, :self.units]\n",
    "            z1 = z[:, self.units: 2 * self.units]\n",
    "            z2 = z[:, 2 * self.units: 3 * self.units]\n",
    "            z3 = z[:, 3 * self.units:]\n",
    "\n",
    "            i = self.recurrent_activation(z0)\n",
    "            f = self.recurrent_activation(z1)\n",
    "            c = f * c_tm1 + i * self.activation(z2)\n",
    "            o = self.recurrent_activation(z3)\n",
    "\n",
    "        h = o * self.activation(c)\n",
    "        if 0 < self.dropout + self.recurrent_dropout:\n",
    "            if training is None:\n",
    "                h._uses_learning_phase = True\n",
    "        return h, [h, c]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: (156060, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>of escapades demonstrating the adage that what...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>escapades demonstrating the adage that what is...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>escapades</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>demonstrating the adage that what is good for ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "5         6           1  of escapades demonstrating the adage that what...   \n",
       "6         7           1                                                 of   \n",
       "7         8           1  escapades demonstrating the adage that what is...   \n",
       "8         9           1                                          escapades   \n",
       "9        10           1  demonstrating the adage that what is good for ...   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  \n",
       "5          2  \n",
       "6          2  \n",
       "7          2  \n",
       "8          2  \n",
       "9          2  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_train = pd.read_csv('train.tsv', sep='\\t')\n",
    "print('train set: {0}'.format(df_train.shape))\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set: (66292, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>156066</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>156067</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>156068</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>156069</td>\n",
       "      <td>8545</td>\n",
       "      <td>pleasing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>156070</td>\n",
       "      <td>8545</td>\n",
       "      <td>but</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
       "2    156063        8545                                                 An\n",
       "3    156064        8545  intermittently pleasing but mostly routine effort\n",
       "4    156065        8545         intermittently pleasing but mostly routine\n",
       "5    156066        8545                        intermittently pleasing but\n",
       "6    156067        8545                            intermittently pleasing\n",
       "7    156068        8545                                     intermittently\n",
       "8    156069        8545                                           pleasing\n",
       "9    156070        8545                                                but"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.tsv', sep='\\t')\n",
    "print('test set: {0}'.format(df_test.shape))\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_list = {r\"i'm\": 'i am',\n",
    "                r\"'re\": ' are',\n",
    "                r\"let’s\": 'let us',\n",
    "                r\"'s\":  ' is',\n",
    "                r\"'ve\": ' have',\n",
    "                r\"can't\": 'can not',\n",
    "                r\"cannot\": 'can not',\n",
    "                r\"shan’t\": 'shall not',\n",
    "                r\"n't\": ' not',\n",
    "                r\"'d\": ' would',\n",
    "                r\"'ll\": ' will',\n",
    "                r\"'scuse\": 'excuse',\n",
    "                ',': ' ,',\n",
    "                '.': ' .',\n",
    "                '!': ' !',\n",
    "                '?': ' ?',\n",
    "                '\\s+': ' '}\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    for s in replace_list:\n",
    "        text = text.replace(s, replace_list[s])\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train['Phrase'].apply(lambda p: clean_text(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max phrase len: 53\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "phrase_len = X_train.apply(lambda p: len(p.split(' ')))\n",
    "max_phrase_len = phrase_len.max()\n",
    "print('max phrase len: {0}'.format(max_phrase_len))\n",
    "plt.figure(figsize = (10, 8))\n",
    "plt.hist(phrase_len, alpha = 0.2, density = True)\n",
    "plt.xlabel('phrase len')\n",
    "plt.ylabel('probability')\n",
    "plt.grid(alpha = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 8192\n",
    "tokenizer = Tokenizer(\n",
    "    num_words = max_words,\n",
    "    filters = '\"#$%&()*+-/:;<=>@[\\]^_`{|}~'\n",
    ")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen = max_phrase_len)\n",
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "epochs = 8\n",
    "\n",
    "lstm = LSTM(2, dropout = 0.3, recurrent_dropout = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 53, 2)             16384     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_7 (Spatial (None, 53, 2)             0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 2)                 40        \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 15        \n",
      "=================================================================\n",
      "Total params: 16,445\n",
      "Trainable params: 16,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(input_dim = max_words, output_dim = 2, input_length = max_phrase_len))\n",
    "model_lstm.add(SpatialDropout1D(0.3))\n",
    "model_lstm.add(lstm)\n",
    "model_lstm.add(Dense(2, activation = 'relu'))\n",
    "model_lstm.add(Dropout(0.3))\n",
    "model_lstm.add(Dense(5, activation = 'softmax'))\n",
    "\n",
    "model_lstm.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding_7 (None, 53) (None, 53, 2)\n",
      "spatial_dropout1d_7 (None, 53, 2) (None, 53, 2)\n",
      "lstm_4 (None, 53, 2) (None, 2)\n",
      "dense_9 (None, 2) (None, 2)\n",
      "dropout_5 (None, 2) (None, 2)\n",
      "dense_10 (None, 2) (None, 5)\n"
     ]
    }
   ],
   "source": [
    "for l in model_lstm.layers:\n",
    "    print (l.name ,l.input_shape,l.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.06526989,  0.73098266,  0.216492  , -0.4776182 ,  0.15904027,\n",
       "         -0.52829576, -0.4858962 ,  0.7484752 ],\n",
       "        [ 0.49711823,  0.01280099,  0.46655333, -0.48079225, -0.02107787,\n",
       "          0.67949593,  0.04307991,  0.17732894]], dtype=float32),\n",
       " array([[-0.27657878,  0.73275286,  0.16077298,  0.14454499,  0.5197249 ,\n",
       "          0.09078886, -0.24794883, -0.00101149],\n",
       "        [-0.48607293, -0.05828494, -0.16193764,  0.44474727, -0.04847855,\n",
       "          0.3184467 ,  0.5376616 ,  0.37877905]], dtype=float32),\n",
       " array([0., 0., 1., 1., 0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'lstm_4/kernel:0' shape=(2, 8) dtype=float32>,\n",
       " <tf.Variable 'lstm_4/recurrent_kernel:0' shape=(2, 8) dtype=float32>,\n",
       " <tf.Variable 'lstm_4/bias:0' shape=(8,) dtype=float32>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140454 samples, validate on 15606 samples\n",
      "Epoch 1/8\n",
      "  3584/140454 [..............................] - ETA: 3:03 - loss: 1.4535 - accuracy: 0.4464"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-38bc9dc4c8e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model_lstm.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split = 0.1,\n",
    "    epochs = 8,\n",
    "    batch_size = 512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.02968112,  0.03597156, -0.01354118, ..., -0.03768282,\n",
       "         -0.04530798, -0.02483854],\n",
       "        [ 0.05838573,  0.05833712,  0.00812168, ...,  0.05591835,\n",
       "         -0.05493913,  0.01831878],\n",
       "        [-0.04771251, -0.05766204, -0.06676204, ..., -0.00069349,\n",
       "         -0.02751125,  0.02011073],\n",
       "        ...,\n",
       "        [ 0.05549449, -0.00820057,  0.00711385, ..., -0.0414844 ,\n",
       "          0.00168291,  0.00126061],\n",
       "        [-0.03992298,  0.02788351,  0.06319727, ..., -0.00913438,\n",
       "         -0.00883676, -0.03685146],\n",
       "        [-0.02418134, -0.00530547, -0.01863088, ...,  0.01666331,\n",
       "          0.00479218,  0.05247296]], dtype=float32),\n",
       " array([[-0.01685544, -0.03643855,  0.03491455, ..., -0.03796409,\n",
       "          0.00122   , -0.00635956],\n",
       "        [ 0.01097   ,  0.00624066, -0.02087489, ..., -0.00792929,\n",
       "          0.04014329,  0.01911935],\n",
       "        [-0.00103643, -0.02223545,  0.01245315, ..., -0.01563763,\n",
       "          0.02655006, -0.0246109 ],\n",
       "        ...,\n",
       "        [ 0.01397585, -0.03611711, -0.0192823 , ...,  0.04030919,\n",
       "          0.03426585,  0.03188378],\n",
       "        [-0.04664538,  0.01644928, -0.02336403, ..., -0.01354402,\n",
       "         -0.03994644, -0.00365791],\n",
       "        [ 0.03941427, -0.02553928, -0.01102687, ...,  0.04253608,\n",
       "          0.02753414,  0.01189666]], dtype=float32),\n",
       " array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.layers[2].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
