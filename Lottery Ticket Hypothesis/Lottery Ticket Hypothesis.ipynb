{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lottery Ticket Hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy\n",
    "import tensorflow\n",
    "from sklearn import preprocessing, model_selection\n",
    "from lottery_ticket_hypothesis import PrunableDense\n",
    "from tensorflow.keras import models, layers, activations\n",
    "from tensorflow import optimizers, initializers, losses, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tries to enable dynamic memory allocation on GPUs\n",
    "try:\n",
    "    for i in tensorflow.config.experimental.list_physical_devices(\"GPU\"):\n",
    "        tensorflow.config.experimental.set_memory_growth(i, True)\n",
    "except:\n",
    "    print(\"Dynamic memory allocation failed on GPU device!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neural_network_prunable():\n",
    "    \"\"\"Prunable model of a fully-connected multilayer perceptron\"\"\"\n",
    "    net = models.Sequential()\n",
    "    net.add(PrunableDense(256, activation=activations.softsign, name=\"Dense0\", bias_initializer=tensorflow.ones, kernel_initializer=initializers.he_normal()))\n",
    "    net.add(PrunableDense(128, activation=activations.softsign, name=\"Dense1\", bias_initializer=tensorflow.ones, kernel_initializer=initializers.he_normal()))\n",
    "    net.add(PrunableDense(64, activation=activations.softsign, name=\"Dense2\", bias_initializer=tensorflow.ones, kernel_initializer=initializers.he_normal()))\n",
    "    net.add(PrunableDense(32, activation=activations.softsign, name=\"Dense3\", bias_initializer=tensorflow.ones, kernel_initializer=initializers.he_normal()))\n",
    "    net.add(PrunableDense(1, activation=activations.tanh, name=\"Output\", bias_initializer=tensorflow.ones, kernel_initializer=initializers.he_normal()))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data reading and train/test separation\n",
    "X = numpy.loadtxt(\"poco_1.prn\", skiprows=11, usecols=(1, 2, 3, 4, 5, 6, 7), dtype=numpy.float32)\n",
    "y_str = numpy.loadtxt(\"poco_1.prn\", skiprows=11, usecols=8, dtype=numpy.str)\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(list(set(y_str)))\n",
    "y = label_encoder.transform(y_str)\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prunable network:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Dense0 (PrunableDense)       multiple                  2048      \n",
      "_________________________________________________________________\n",
      "Dense1 (PrunableDense)       multiple                  32896     \n",
      "_________________________________________________________________\n",
      "Dense2 (PrunableDense)       multiple                  8256      \n",
      "_________________________________________________________________\n",
      "Dense3 (PrunableDense)       multiple                  2080      \n",
      "_________________________________________________________________\n",
      "Output (PrunableDense)       multiple                  33        \n",
      "=================================================================\n",
      "Total params: 45,313\n",
      "Trainable params: 45,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Building model\n",
    "print(\"Prunable network:\")\n",
    "nn = create_neural_network_prunable()\n",
    "nn.build(x_train.shape)\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving initial values\n",
    "for i in nn.layers:\n",
    "    i.save_kernel()\n",
    "    i.save_bias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before pruning:\n",
      "Train on 1134 samples, validate on 1134 samples\n",
      "Epoch 1/10\n",
      "1134/1134 [==============================] - 2s 1ms/sample - loss: 0.7922 - binary_accuracy: 0.4612 - val_loss: 0.5773 - val_binary_accuracy: 0.6684\n",
      "Epoch 2/10\n",
      "1134/1134 [==============================] - 0s 90us/sample - loss: 0.5043 - binary_accuracy: 0.7143 - val_loss: 0.4227 - val_binary_accuracy: 0.8254\n",
      "Epoch 3/10\n",
      "1134/1134 [==============================] - 0s 91us/sample - loss: 0.3557 - binary_accuracy: 0.8730 - val_loss: 0.3010 - val_binary_accuracy: 0.9021\n",
      "Epoch 4/10\n",
      "1134/1134 [==============================] - 0s 98us/sample - loss: 0.3126 - binary_accuracy: 0.9083 - val_loss: 0.2773 - val_binary_accuracy: 0.9162\n",
      "Epoch 5/10\n",
      "1134/1134 [==============================] - 0s 92us/sample - loss: 0.2840 - binary_accuracy: 0.9153 - val_loss: 0.2915 - val_binary_accuracy: 0.9127\n",
      "Epoch 6/10\n",
      "1134/1134 [==============================] - 0s 91us/sample - loss: 0.3006 - binary_accuracy: 0.9145 - val_loss: 0.2849 - val_binary_accuracy: 0.9162\n",
      "Epoch 7/10\n",
      "1134/1134 [==============================] - 0s 97us/sample - loss: 0.2804 - binary_accuracy: 0.9180 - val_loss: 0.3125 - val_binary_accuracy: 0.9145\n",
      "Epoch 8/10\n",
      "1134/1134 [==============================] - 0s 97us/sample - loss: 0.2922 - binary_accuracy: 0.9171 - val_loss: 0.2613 - val_binary_accuracy: 0.9127\n",
      "Epoch 9/10\n",
      "1134/1134 [==============================] - 0s 91us/sample - loss: 0.2567 - binary_accuracy: 0.9145 - val_loss: 0.2516 - val_binary_accuracy: 0.9153\n",
      "Epoch 10/10\n",
      "1134/1134 [==============================] - 0s 93us/sample - loss: 0.2513 - binary_accuracy: 0.9206 - val_loss: 0.2476 - val_binary_accuracy: 0.9233\n",
      "Loss: 0.26022160391794763\n",
      "Accuracy: 0.90518785\n"
     ]
    }
   ],
   "source": [
    "#compiling, training and evaluating model\n",
    "nn.compile(optimizer=optimizers.Adam(learning_rate=0.0001), loss=losses.BinaryCrossentropy(), metrics=[metrics.BinaryAccuracy()])\n",
    "print(\"Before pruning:\")\n",
    "nn.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_train, y_train))\n",
    "loss, accuracy = nn.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = []\n",
    "for layer in nn.layers:\n",
    "    l1.append(tensorflow.reshape(layer.kernel, (-1,))[tensorflow.reshape(layer.trainable_channels, (-1,)) == 1])\n",
    "    l1.append(tensorflow.reshape(layer.bias, (-1,))[tensorflow.reshape(layer.trainable_bias, (-1,)) == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tensorflow.sort(tensorflow.concat(l1, axis=-1))\n",
    "p = int(numpy.floor((9. / 10.) * len(s)))\n",
    "threshold = s[p].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in nn.layers:\n",
    "    indices_kernel = tensorflow.where(layer.kernel < threshold)\n",
    "    indices_bias = tensorflow.where(layer.bias < threshold)\n",
    "    t1 = tensorflow.tensor_scatter_nd_update(tensorflow.ones(layer.kernel.shape), indices_kernel, tensorflow.zeros(len(indices_kernel)))\n",
    "    t2 = tensorflow.tensor_scatter_nd_update(tensorflow.ones(layer.bias.shape), indices_bias, tensorflow.zeros(len(indices_bias)))\n",
    "    layer.prune_kernel(t1)\n",
    "    layer.prune_bias(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restoring initial values\n",
    "for i in nn.layers:\n",
    "    i.restore_kernel()\n",
    "    i.restore_bias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pruning:\n",
      "Train on 1134 samples, validate on 1134 samples\n",
      "Epoch 1/10\n",
      "1134/1134 [==============================] - 0s 106us/sample - loss: 0.9295 - binary_accuracy: 0.3369 - val_loss: 0.7372 - val_binary_accuracy: 0.3369\n",
      "Epoch 2/10\n",
      "1134/1134 [==============================] - 0s 91us/sample - loss: 0.6407 - binary_accuracy: 0.6526 - val_loss: 0.5695 - val_binary_accuracy: 0.7046\n",
      "Epoch 3/10\n",
      "1134/1134 [==============================] - 0s 93us/sample - loss: 0.5305 - binary_accuracy: 0.6808 - val_loss: 0.4824 - val_binary_accuracy: 0.7734\n",
      "Epoch 4/10\n",
      "1134/1134 [==============================] - 0s 92us/sample - loss: 0.4329 - binary_accuracy: 0.8201 - val_loss: 0.3745 - val_binary_accuracy: 0.8598\n",
      "Epoch 5/10\n",
      "1134/1134 [==============================] - 0s 94us/sample - loss: 0.3438 - binary_accuracy: 0.8889 - val_loss: 0.3114 - val_binary_accuracy: 0.8968\n",
      "Epoch 6/10\n",
      "1134/1134 [==============================] - 0s 95us/sample - loss: 0.2957 - binary_accuracy: 0.9048 - val_loss: 0.2982 - val_binary_accuracy: 0.9056\n",
      "Epoch 7/10\n",
      "1134/1134 [==============================] - 0s 94us/sample - loss: 0.4613 - binary_accuracy: 0.8245 - val_loss: 0.5088 - val_binary_accuracy: 0.8457\n",
      "Epoch 8/10\n",
      "1134/1134 [==============================] - 0s 100us/sample - loss: 0.4161 - binary_accuracy: 0.9039 - val_loss: 0.3420 - val_binary_accuracy: 0.9065\n",
      "Epoch 9/10\n",
      "1134/1134 [==============================] - 0s 98us/sample - loss: 0.3232 - binary_accuracy: 0.9012 - val_loss: 0.3076 - val_binary_accuracy: 0.8995\n",
      "Epoch 10/10\n",
      "1134/1134 [==============================] - 0s 96us/sample - loss: 0.2976 - binary_accuracy: 0.9056 - val_loss: 0.2860 - val_binary_accuracy: 0.9083\n",
      "Loss: 0.2964909312603512\n",
      "Accuracy: 0.88729876\n"
     ]
    }
   ],
   "source": [
    "#Training again\n",
    "print(\"After pruning:\")\n",
    "nn.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_train, y_train))\n",
    "loss, accuracy = nn.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active edges:\n",
      "Dense0 : tf.Tensor(728, shape=(), dtype=int64)\n",
      "Dense1 : tf.Tensor(1723, shape=(), dtype=int64)\n",
      "Dense2 : tf.Tensor(1123, shape=(), dtype=int64)\n",
      "Dense3 : tf.Tensor(465, shape=(), dtype=int64)\n",
      "Output : tf.Tensor(12, shape=(), dtype=int64)\n",
      "Total: 4051\n"
     ]
    }
   ],
   "source": [
    "#Printing active edges\n",
    "print(\"Active edges:\")\n",
    "t = tensorflow.Variable(0, dtype=tensorflow.int64)\n",
    "for i in nn.layers:\n",
    "    j = tensorflow.math.count_nonzero(i.trainable_channels)\n",
    "    t.assign_add(j)\n",
    "    print(i.name, \":\", j)\n",
    "print(\"Total:\", t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disabled edges:\n",
      "Dense0 : tf.Tensor(1064, shape=(), dtype=int64)\n",
      "Dense1 : tf.Tensor(31045, shape=(), dtype=int64)\n",
      "Dense2 : tf.Tensor(7069, shape=(), dtype=int64)\n",
      "Dense3 : tf.Tensor(1583, shape=(), dtype=int64)\n",
      "Output : tf.Tensor(20, shape=(), dtype=int64)\n",
      "Total: 40781\n"
     ]
    }
   ],
   "source": [
    "print(\"Disabled edges:\")\n",
    "for i in nn.layers:\n",
    "    j = tensorflow.reduce_sum(tensorflow.cast((i.trainable_channels == 0), dtype=tensorflow.int64))\n",
    "    t.assign_add(j)\n",
    "    print(i.name, \":\", j)\n",
    "print(\"Total:\", t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
