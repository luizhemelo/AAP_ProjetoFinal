{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lottery Ticket Hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy\n",
    "import tensorflow\n",
    "from sklearn import preprocessing, model_selection\n",
    "from lottery_ticket_hypothesis import PrunableDense\n",
    "from tensorflow.keras import models, layers, activations\n",
    "from tensorflow import optimizers, initializers, losses, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tries to enable dynamic memory allocation on GPUs\n",
    "try:\n",
    "    for i in tensorflow.config.experimental.list_physical_devices(\"GPU\"):\n",
    "        tensorflow.config.experimental.set_memory_growth(i, True)\n",
    "except:\n",
    "    print(\"Dynamic memory allocation failed on GPU device!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neural_network_prunable():\n",
    "    \"\"\"Prunable model of a fully-connected multilayer perceptron\"\"\"\n",
    "    net = models.Sequential()\n",
    "    net.add(PrunableDense(256, activation=activations.softsign, name=\"Dense0\", bias_initializer=tensorflow.ones, kernel_initializer=initializers.he_normal()))\n",
    "    net.add(PrunableDense(128, activation=activations.softsign, name=\"Dense1\", bias_initializer=tensorflow.ones, kernel_initializer=initializers.he_normal()))\n",
    "    net.add(PrunableDense(64, activation=activations.softsign, name=\"Dense2\", bias_initializer=tensorflow.ones, kernel_initializer=initializers.he_normal()))\n",
    "    net.add(PrunableDense(32, activation=activations.softsign, name=\"Dense3\", bias_initializer=tensorflow.ones, kernel_initializer=initializers.he_normal()))\n",
    "    net.add(PrunableDense(1, activation=activations.tanh, name=\"Output\", bias_initializer=tensorflow.ones, kernel_initializer=initializers.he_normal()))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data reading and train/test separation\n",
    "X = numpy.loadtxt(\"poco_1.prn\", skiprows=11, usecols=(1, 2, 3, 4, 5, 6, 7), dtype=numpy.float32)\n",
    "y_str = numpy.loadtxt(\"poco_1.prn\", skiprows=11, usecols=8, dtype=numpy.str)\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(list(set(y_str)))\n",
    "y = label_encoder.transform(y_str)\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prunable network:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Dense0 (PrunableDense)       multiple                  2048      \n",
      "_________________________________________________________________\n",
      "Dense1 (PrunableDense)       multiple                  32896     \n",
      "_________________________________________________________________\n",
      "Dense2 (PrunableDense)       multiple                  8256      \n",
      "_________________________________________________________________\n",
      "Dense3 (PrunableDense)       multiple                  2080      \n",
      "_________________________________________________________________\n",
      "Output (PrunableDense)       multiple                  33        \n",
      "=================================================================\n",
      "Total params: 45,313\n",
      "Trainable params: 45,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Before pruning:\n",
      "Train on 1134 samples, validate on 1134 samples\n",
      "Epoch 1/10\n",
      "1134/1134 [==============================] - 2s 2ms/sample - loss: 0.5278 - binary_accuracy: 0.7363 - val_loss: 0.4452 - val_binary_accuracy: 0.7557\n",
      "Epoch 2/10\n",
      "1134/1134 [==============================] - 0s 167us/sample - loss: 0.4116 - binary_accuracy: 0.8483 - val_loss: 0.4092 - val_binary_accuracy: 0.8810\n",
      "Epoch 3/10\n",
      "1134/1134 [==============================] - 0s 188us/sample - loss: 0.4114 - binary_accuracy: 0.8889 - val_loss: 0.3446 - val_binary_accuracy: 0.9145\n",
      "Epoch 4/10\n",
      "1134/1134 [==============================] - 0s 246us/sample - loss: 0.3475 - binary_accuracy: 0.9109 - val_loss: 0.3287 - val_binary_accuracy: 0.9101\n",
      "Epoch 5/10\n",
      "1134/1134 [==============================] - 0s 253us/sample - loss: 0.3317 - binary_accuracy: 0.9180 - val_loss: 0.3105 - val_binary_accuracy: 0.9189\n",
      "Epoch 6/10\n",
      "1134/1134 [==============================] - 0s 107us/sample - loss: 0.2918 - binary_accuracy: 0.9136 - val_loss: 0.2811 - val_binary_accuracy: 0.9118\n",
      "Epoch 7/10\n",
      "1134/1134 [==============================] - 0s 104us/sample - loss: 0.2769 - binary_accuracy: 0.9145 - val_loss: 0.2712 - val_binary_accuracy: 0.9162\n",
      "Epoch 8/10\n",
      "1134/1134 [==============================] - 0s 108us/sample - loss: 0.2691 - binary_accuracy: 0.9198 - val_loss: 0.2646 - val_binary_accuracy: 0.9206\n",
      "Epoch 9/10\n",
      "1134/1134 [==============================] - 0s 106us/sample - loss: 0.2627 - binary_accuracy: 0.9206 - val_loss: 0.2578 - val_binary_accuracy: 0.9215\n",
      "Epoch 10/10\n",
      "1134/1134 [==============================] - 0s 105us/sample - loss: 0.2679 - binary_accuracy: 0.9215 - val_loss: 0.2682 - val_binary_accuracy: 0.9233\n",
      "Loss: 0.29410275083854925\n",
      "Accuracy: 0.8998211\n"
     ]
    }
   ],
   "source": [
    "#Building, saving initial values of kernel/bias, compiling and training model\n",
    "print(\"Prunable network:\")\n",
    "nn = create_neural_network_prunable()\n",
    "nn.build(x_train.shape)\n",
    "for i in nn.layers:\n",
    "    i.save_kernel()\n",
    "    i.save_bias()\n",
    "nn.summary()\n",
    "nn.compile(optimizer=optimizers.Adam(learning_rate=0.0001), loss=losses.BinaryCrossentropy(), metrics=[metrics.BinaryAccuracy()])\n",
    "print(\"Before pruning:\")\n",
    "nn.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_train, y_train))\n",
    "loss, accuracy = nn.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1, l2 = [], []\n",
    "for layer in nn.layers:\n",
    "    l1.append(tensorflow.reshape(layer.kernel, (-1,)))\n",
    "    l1.append(tensorflow.reshape(layer.bias, (-1,)))\n",
    "    l2.append(tensorflow.reshape(layer.trainable_channels, (-1,)))\n",
    "    l2.append(tensorflow.reshape(layer.trainable_bias, (-1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tensorflow.sort(tensorflow.concat(l1, axis=-1))[tensorflow.concat(l2, axis=-1) == 1]\n",
    "p = int(numpy.floor((9. / 10.) * len(s)))\n",
    "threshold = s[p].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in nn.layers:\n",
    "    indices_kernel = tensorflow.where(layer.kernel < threshold)\n",
    "    indices_bias = tensorflow.where(layer.bias < threshold)\n",
    "    t1 = tensorflow.tensor_scatter_nd_update(tensorflow.ones(layer.kernel.shape), indices_kernel, tensorflow.zeros(len(indices_kernel)))\n",
    "    t2 = tensorflow.tensor_scatter_nd_update(tensorflow.ones(layer.bias.shape), indices_bias, tensorflow.zeros(len(indices_bias)))\n",
    "    layer.prune_kernel(t1)\n",
    "    layer.prune_bias(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restoring initial values\n",
    "for i in nn.layers:\n",
    "    i.restore_kernel()\n",
    "    i.restore_bias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pruning:\n",
      "Train on 1134 samples, validate on 1134 samples\n",
      "Epoch 1/10\n",
      "1134/1134 [==============================] - 0s 113us/sample - loss: 0.5928 - binary_accuracy: 0.8377 - val_loss: 0.5373 - val_binary_accuracy: 0.7954\n",
      "Epoch 2/10\n",
      "1134/1134 [==============================] - 0s 92us/sample - loss: 0.4968 - binary_accuracy: 0.7945 - val_loss: 0.4555 - val_binary_accuracy: 0.8148\n",
      "Epoch 3/10\n",
      "1134/1134 [==============================] - 0s 91us/sample - loss: 0.4300 - binary_accuracy: 0.8333 - val_loss: 0.4025 - val_binary_accuracy: 0.8642\n",
      "Epoch 4/10\n",
      "1134/1134 [==============================] - 0s 82us/sample - loss: 0.3836 - binary_accuracy: 0.8739 - val_loss: 0.3633 - val_binary_accuracy: 0.8862\n",
      "Epoch 5/10\n",
      "1134/1134 [==============================] - 0s 95us/sample - loss: 0.3528 - binary_accuracy: 0.8898 - val_loss: 0.3332 - val_binary_accuracy: 0.8907\n",
      "Epoch 6/10\n",
      "1134/1134 [==============================] - 0s 137us/sample - loss: 0.3236 - binary_accuracy: 0.8968 - val_loss: 0.3109 - val_binary_accuracy: 0.9083\n",
      "Epoch 7/10\n",
      "1134/1134 [==============================] - 0s 154us/sample - loss: 0.3049 - binary_accuracy: 0.9118 - val_loss: 0.2937 - val_binary_accuracy: 0.9136\n",
      "Epoch 8/10\n",
      "1134/1134 [==============================] - 0s 96us/sample - loss: 0.2888 - binary_accuracy: 0.9171 - val_loss: 0.2806 - val_binary_accuracy: 0.9162\n",
      "Epoch 9/10\n",
      "1134/1134 [==============================] - 0s 84us/sample - loss: 0.2790 - binary_accuracy: 0.9171 - val_loss: 0.2786 - val_binary_accuracy: 0.9233\n",
      "Epoch 10/10\n",
      "1134/1134 [==============================] - 0s 103us/sample - loss: 0.2730 - binary_accuracy: 0.9233 - val_loss: 0.2653 - val_binary_accuracy: 0.9224\n",
      "Loss: 0.28566777157015794\n",
      "Accuracy: 0.8980322\n"
     ]
    }
   ],
   "source": [
    "#Training again\n",
    "print(\"After pruning:\")\n",
    "nn.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_train, y_train))\n",
    "loss, accuracy = nn.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active edges:\n",
      "Dense0 : tf.Tensor(712, shape=(), dtype=int64)\n",
      "Dense1 : tf.Tensor(1833, shape=(), dtype=int64)\n",
      "Dense2 : tf.Tensor(1035, shape=(), dtype=int64)\n",
      "Dense3 : tf.Tensor(463, shape=(), dtype=int64)\n",
      "Output : tf.Tensor(8, shape=(), dtype=int64)\n",
      "Total: 4051\n"
     ]
    }
   ],
   "source": [
    "#Printing active edges\n",
    "print(\"Active edges:\")\n",
    "t = tensorflow.Variable(0, dtype=tensorflow.int64)\n",
    "for i in nn.layers:\n",
    "    j = tensorflow.math.count_nonzero(i.trainable_channels)\n",
    "    t.assign_add(j)\n",
    "    print(i.name, \":\", j)\n",
    "print(\"Total:\", t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disabled edges:\n",
      "Dense0 : tf.Tensor(1080, shape=(), dtype=int64)\n",
      "Dense1 : tf.Tensor(30935, shape=(), dtype=int64)\n",
      "Dense2 : tf.Tensor(7157, shape=(), dtype=int64)\n",
      "Dense3 : tf.Tensor(1585, shape=(), dtype=int64)\n",
      "Output : tf.Tensor(24, shape=(), dtype=int64)\n",
      "Total: 40781\n"
     ]
    }
   ],
   "source": [
    "print(\"Disabled edges:\")\n",
    "for i in nn.layers:\n",
    "    j = tensorflow.reduce_sum(tensorflow.cast((i.trainable_channels == 0), dtype=tensorflow.int64))\n",
    "    t.assign_add(j)\n",
    "    print(i.name, \":\", j)\n",
    "print(\"Total:\", t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
