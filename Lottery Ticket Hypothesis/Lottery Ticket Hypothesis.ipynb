{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy\n",
    "import tensorflow\n",
    "from sklearn import preprocessing, model_selection\n",
    "from lottery_ticket_hypothesis import PrunableDense\n",
    "from tensorflow.keras import models, layers, activations\n",
    "from tensorflow import optimizers, initializers, losses, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tries to enable dynamic memory allocation on GPUs\n",
    "try:\n",
    "    for i in tensorflow.config.experimental.list_physical_devices(\"GPU\"):\n",
    "        tensorflow.config.experimental.set_memory_growth(i, True)\n",
    "except:\n",
    "    print(\"Dynamic memory allocation failed on GPU device \" + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neural_network_prunable():\n",
    "    \"\"\"Prunable model of a fully-connected multilayer perceptron\"\"\"\n",
    "    net = models.Sequential()\n",
    "    net.add(PrunableDense(256, activation=activations.softsign, name=\"Dense0\", bias_initializer=tensorflow.ones, kernel_initializer=initializers.he_normal()))\n",
    "    net.add(PrunableDense(128, activation=activations.softsign, name=\"Dense1\", bias_initializer=tensorflow.ones, kernel_initializer=initializers.he_normal()))\n",
    "    net.add(PrunableDense(64, activation=activations.softsign, name=\"Dense2\", bias_initializer=tensorflow.ones, kernel_initializer=initializers.he_normal()))\n",
    "    net.add(PrunableDense(32, activation=activations.softsign, name=\"Dense3\", bias_initializer=tensorflow.ones, kernel_initializer=initializers.he_normal()))\n",
    "    net.add(PrunableDense(1, activation=activations.tanh, name=\"Output\", bias_initializer=tensorflow.ones, kernel_initializer=initializers.he_normal()))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data reading and train/test separation\n",
    "X = numpy.loadtxt(\"poco_1.prn\", skiprows=11, usecols=(1, 2, 3, 4, 5, 6, 7), dtype=numpy.float32)\n",
    "y_str = numpy.loadtxt(\"poco_1.prn\", skiprows=11, usecols=8, dtype=numpy.str)\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(list(set(y_str)))\n",
    "y = label_encoder.transform(y_str)\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prunable network:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Dense0 (PrunableDense)       multiple                  2048      \n",
      "_________________________________________________________________\n",
      "Dense1 (PrunableDense)       multiple                  32896     \n",
      "_________________________________________________________________\n",
      "Dense2 (PrunableDense)       multiple                  8256      \n",
      "_________________________________________________________________\n",
      "Dense3 (PrunableDense)       multiple                  2080      \n",
      "_________________________________________________________________\n",
      "Output (PrunableDense)       multiple                  33        \n",
      "=================================================================\n",
      "Total params: 45,313\n",
      "Trainable params: 45,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Before pruning:\n",
      "Train on 1134 samples, validate on 1134 samples\n",
      "Epoch 1/10\n",
      "1134/1134 [==============================] - 1s 1ms/sample - loss: 1.5093 - binary_accuracy: 0.6631 - val_loss: 0.6372 - val_binary_accuracy: 0.6649\n",
      "Epoch 2/10\n",
      "1134/1134 [==============================] - 0s 99us/sample - loss: 0.6117 - binary_accuracy: 0.6649 - val_loss: 0.5666 - val_binary_accuracy: 0.6631\n",
      "Epoch 3/10\n",
      "1134/1134 [==============================] - 0s 92us/sample - loss: 0.5333 - binary_accuracy: 0.6631 - val_loss: 0.4904 - val_binary_accuracy: 0.6631\n",
      "Epoch 4/10\n",
      "1134/1134 [==============================] - 0s 92us/sample - loss: 0.4562 - binary_accuracy: 0.6631 - val_loss: 0.4124 - val_binary_accuracy: 0.6940\n",
      "Epoch 5/10\n",
      "1134/1134 [==============================] - 0s 92us/sample - loss: 0.4279 - binary_accuracy: 0.8501 - val_loss: 0.4501 - val_binary_accuracy: 0.9162\n",
      "Epoch 6/10\n",
      "1134/1134 [==============================] - 0s 92us/sample - loss: 0.4338 - binary_accuracy: 0.9127 - val_loss: 0.3892 - val_binary_accuracy: 0.9083\n",
      "Epoch 7/10\n",
      "1134/1134 [==============================] - 0s 92us/sample - loss: 0.3623 - binary_accuracy: 0.8977 - val_loss: 0.3415 - val_binary_accuracy: 0.8907\n",
      "Epoch 8/10\n",
      "1134/1134 [==============================] - 0s 92us/sample - loss: 0.3445 - binary_accuracy: 0.9030 - val_loss: 0.3955 - val_binary_accuracy: 0.9189\n",
      "Epoch 9/10\n",
      "1134/1134 [==============================] - 0s 92us/sample - loss: 0.4232 - binary_accuracy: 0.9189 - val_loss: 0.3993 - val_binary_accuracy: 0.9215\n",
      "Epoch 10/10\n",
      "1134/1134 [==============================] - 0s 85us/sample - loss: 0.3628 - binary_accuracy: 0.9153 - val_loss: 0.3285 - val_binary_accuracy: 0.9092\n",
      "Loss: 0.3304378742715327\n",
      "Accuracy: 0.90339893\n"
     ]
    }
   ],
   "source": [
    "#Building, saving initial values of kernel/bias, compiling and training model\n",
    "print(\"Prunable network:\")\n",
    "nn = create_neural_network_prunable()\n",
    "nn.build(x_train.shape)\n",
    "for i in nn.layers:\n",
    "    i.save_kernel()\n",
    "    i.save_bias()\n",
    "nn.summary()\n",
    "nn.compile(optimizer=optimizers.Adam(learning_rate=0.0001), loss=losses.BinaryCrossentropy(), metrics=[metrics.BinaryAccuracy()])\n",
    "print(\"Before pruning:\")\n",
    "nn.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_train, y_train))\n",
    "loss, accuracy = nn.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating list of weights, saving weight value and index\n",
    "#TODO optimize?\n",
    "l = []\n",
    "for i in range(len(nn.layers)):\n",
    "    t1, t2 = nn.layers[i].kernel, nn.layers[i].bias\n",
    "    for j in range(t1.shape[0]):\n",
    "        for k in range(t1[j].shape[0]):\n",
    "            l.append((t1[j][k].numpy(), i, j, k))\n",
    "    for j in range(t2.shape[0]):\n",
    "        l.append((t2[j].numpy(), i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting weights for pruning\n",
    "#TODO change p to p**(1/n)\n",
    "s = sorted(l, key=lambda x: x[0])\n",
    "del l\n",
    "p = int(numpy.floor((9. / 10.) * len(s)))\n",
    "s = s[:p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dictionaries for separating weights and bias by layer\n",
    "to_prune_dict_kernel, to_prune_dict_bias = {}, {}\n",
    "for i in range(len(nn.layers)):\n",
    "    to_prune_dict_kernel[i] = []\n",
    "    to_prune_dict_bias[i] = []\n",
    "for i in s:\n",
    "    if len(i) > 3:\n",
    "        to_prune_dict_kernel[i[1]].append(i[2:])\n",
    "    else:\n",
    "        to_prune_dict_bias[i[1]].append(i[2])\n",
    "del s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating pruning Tensor for pruning weights and pruning each layer kernel\n",
    "for i in to_prune_dict_kernel.keys():\n",
    "    if not to_prune_dict_kernel[i]:\n",
    "        continue\n",
    "    v = tensorflow.Variable(tensorflow.ones(nn.layers[i].kernel.shape))\n",
    "    u = tensorflow.Variable(tensorflow.zeros(len(to_prune_dict_kernel[i])))\n",
    "    t = tensorflow.tensor_scatter_nd_update(v, to_prune_dict_kernel[i], u)\n",
    "    if tensorflow.math.reduce_any(t == 0):\n",
    "        nn.layers[i].prune_kernel(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating pruning Tensor for bias and pruning each layer\n",
    "for i in to_prune_dict_bias.keys():\n",
    "    if not to_prune_dict_bias[i]:\n",
    "        continue\n",
    "    v = tensorflow.Variable(tensorflow.ones(nn.layers[i].bias.shape))\n",
    "    u = tensorflow.Variable(tensorflow.zeros(len(to_prune_dict_bias[i])))\n",
    "    t = tensorflow.tensor_scatter_nd_update(v, to_prune_dict_bias[i], u)\n",
    "    if tensorflow.math.reduce_any(t == 0):\n",
    "        nn.layers[i].prune_bias(t)\n",
    "del to_prune_dict_bias, to_prune_dict_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Restoring initial values\n",
    "for i in nn.layers:\n",
    "    i.restore_kernel()\n",
    "    i.restore_bias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pruning:\n",
      "Train on 1134 samples, validate on 1134 samples\n",
      "Epoch 1/10\n",
      "1134/1134 [==============================] - 0s 106us/sample - loss: 5.1040 - binary_accuracy: 0.6631 - val_loss: 4.9988 - val_binary_accuracy: 0.6631\n",
      "Epoch 2/10\n",
      "1134/1134 [==============================] - 0s 92us/sample - loss: 1.5554 - binary_accuracy: 0.6464 - val_loss: 0.6645 - val_binary_accuracy: 0.5494\n",
      "Epoch 3/10\n",
      "1134/1134 [==============================] - 0s 92us/sample - loss: 0.6716 - binary_accuracy: 0.6605 - val_loss: 0.6525 - val_binary_accuracy: 0.7681\n",
      "Epoch 4/10\n",
      "1134/1134 [==============================] - 0s 92us/sample - loss: 0.6210 - binary_accuracy: 0.8131 - val_loss: 0.5858 - val_binary_accuracy: 0.6922\n",
      "Epoch 5/10\n",
      "1134/1134 [==============================] - 0s 134us/sample - loss: 0.5604 - binary_accuracy: 0.6614 - val_loss: 0.5353 - val_binary_accuracy: 0.6631\n",
      "Epoch 6/10\n",
      "1134/1134 [==============================] - 0s 113us/sample - loss: 0.5181 - binary_accuracy: 0.6631 - val_loss: 0.5010 - val_binary_accuracy: 0.6631\n",
      "Epoch 7/10\n",
      "1134/1134 [==============================] - 0s 79us/sample - loss: 0.4872 - binary_accuracy: 0.6631 - val_loss: 0.4714 - val_binary_accuracy: 0.6631\n",
      "Epoch 8/10\n",
      "1134/1134 [==============================] - 0s 93us/sample - loss: 0.4585 - binary_accuracy: 0.6631 - val_loss: 0.4432 - val_binary_accuracy: 0.6631\n",
      "Epoch 9/10\n",
      "1134/1134 [==============================] - 0s 92us/sample - loss: 0.4307 - binary_accuracy: 0.6631 - val_loss: 0.4162 - val_binary_accuracy: 0.6631\n",
      "Epoch 10/10\n",
      "1134/1134 [==============================] - 0s 92us/sample - loss: 0.4042 - binary_accuracy: 0.7487 - val_loss: 0.3909 - val_binary_accuracy: 0.8263\n",
      "Loss: 0.3801594892106884\n",
      "Accuracy: 0.842576\n"
     ]
    }
   ],
   "source": [
    "#Training again\n",
    "print(\"After pruning:\")\n",
    "nn.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_train, y_train))\n",
    "loss, accuracy = nn.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active edges:\n",
      "Dense0 : tf.Tensor(722, shape=(), dtype=int64)\n",
      "Dense1 : tf.Tensor(1757, shape=(), dtype=int64)\n",
      "Dense2 : tf.Tensor(1134, shape=(), dtype=int64)\n",
      "Dense3 : tf.Tensor(430, shape=(), dtype=int64)\n",
      "Output : tf.Tensor(8, shape=(), dtype=int64)\n",
      "Total: 4051\n"
     ]
    }
   ],
   "source": [
    "#Printing active edges\n",
    "print(\"Active edges:\")\n",
    "t = tensorflow.Variable(0, dtype=tensorflow.int64)\n",
    "for i in nn.layers:\n",
    "    j = tensorflow.math.count_nonzero(i.trainable_channels)\n",
    "    t.assign_add(j)\n",
    "    print(i.name, \":\", j)\n",
    "print(\"Total:\", t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disabled edges:\n",
      "Dense0 : tf.Tensor(1070, shape=(), dtype=int64)\n",
      "Dense1 : tf.Tensor(31011, shape=(), dtype=int64)\n",
      "Dense2 : tf.Tensor(7058, shape=(), dtype=int64)\n",
      "Dense3 : tf.Tensor(1618, shape=(), dtype=int64)\n",
      "Output : tf.Tensor(24, shape=(), dtype=int64)\n",
      "Total: 40781\n"
     ]
    }
   ],
   "source": [
    "print(\"Disabled edges:\")\n",
    "for i in nn.layers:\n",
    "\tj = tensorflow.reduce_sum(tensorflow.cast((i.trainable_channels == 0), dtype=tensorflow.int64))\n",
    "\tt.assign_add(j)\n",
    "\tprint(i.name, \":\", j)\n",
    "print(\"Total:\", t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
